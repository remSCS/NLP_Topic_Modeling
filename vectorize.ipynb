{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this file is to vectorize sentences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install the transformers library\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub \n",
    "# from tensorflow.keras import layers \n",
    "# import bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import word2vec\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_excel('datasets/all_train_data.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "train['avis_en_cleaned'] = train['avis_en'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop_words)]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "train['tokenized'] = train['avis_en_cleaned'].apply(lambda x: str(x).split())\n",
    "\n",
    "# Create the model\n",
    "model_word2vec = word2vec.Word2Vec(train['tokenized'], min_count=1, vector_size=400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle BERT en utilisant la fonction \"from_pretrained\" de la classe \"BertModel\"\n",
    "model_BERT = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenizer vos données en utilisant la classe \"BertTokenizer\"\n",
    "tokenizer_BERT = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Même format que ta tokenization précédente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_text = [tokenizer_BERT.tokenize(sent) for sent in train['avis_en_cleaned']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization BERT avec encode_plus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joindre tous les commentaires de manière à avoir un texte\n",
    "avis_en_cleaned_str = [''.join(i) for i in train['avis_en_cleaned']]\n",
    "avis_en_cleaned_str = ' '.join(avis_en_cleaned_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les données tokenizées en tensors en utilisant la fonction \"encode_plus\" de la classe \"BertTokenizer\"\n",
    "encoding_BERT = tokenizer_BERT.encode_plus(avis_en_cleaned_str, \n",
    "                                            add_special_tokens = True,    \n",
    "                                            truncation = True, \n",
    "                                            padding = \"max_length\", \n",
    "                                            return_attention_mask = True, \n",
    "                                            return_tensors = \"pt\")\n",
    "\n",
    "# Générer les embeddings\n",
    "output = model_BERT(**encoding_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.5753e-01, -2.1523e-01,  8.6006e-01, -2.6880e-01, -3.4727e-02,\n",
      "         -3.9694e-03,  7.8232e-01,  1.7451e-01,  1.8797e-01, -5.5796e-01,\n",
      "          8.5268e-03,  5.1396e-02, -5.3375e-02,  9.6717e-02, -5.8245e-01,\n",
      "          4.3922e-02,  6.2102e-01,  3.9938e-02, -1.5353e-01,  9.1402e-02,\n",
      "         -7.8941e-03, -4.2214e-01,  7.8925e-01, -2.3728e-01,  3.1339e-01,\n",
      "         -4.7162e-01, -4.8409e-01, -3.6018e-01, -4.6085e-01,  4.2710e-01,\n",
      "          1.8886e-01,  3.4104e-01, -9.0609e-02, -2.3729e-01,  1.7343e-01,\n",
      "         -1.1408e-01,  5.5881e-01, -3.6389e-02,  2.9742e-01, -1.5055e-01,\n",
      "          4.8682e-01,  2.8704e-01, -5.9464e-02, -1.4784e-02,  1.1381e-01,\n",
      "          4.4457e-02, -3.8195e+00,  2.4079e-01, -1.5132e-01, -3.7325e-01,\n",
      "          5.7998e-01, -7.2593e-01, -3.9227e-01,  1.7995e-01, -7.0363e-03,\n",
      "          1.0834e-01,  1.1508e-01, -4.8181e-01,  5.3446e-01, -2.7211e-01,\n",
      "          2.9117e-01, -1.7528e-01,  5.2627e-01,  1.5731e-01,  2.8126e-01,\n",
      "          2.3845e-01, -1.0989e-01,  8.8776e-02, -2.3742e-01,  1.3465e-01,\n",
      "         -2.2288e-01, -2.3911e-01,  1.0240e-01,  2.4459e-02, -1.3634e-01,\n",
      "         -8.7677e-01, -6.6463e-01,  6.2440e-01,  3.2347e-02, -1.5474e-01,\n",
      "         -5.0703e-02,  3.7308e-01, -1.1644e-01, -3.1663e-01, -5.8165e-03,\n",
      "          3.6775e-01,  5.9700e-01,  1.2844e-01, -7.1592e-01,  5.4314e-01,\n",
      "          5.3524e-01, -3.2627e-01, -6.3740e-02, -7.8135e-02, -1.7483e-01,\n",
      "          1.4360e-01,  3.6811e-01,  5.7721e-02,  1.1827e-02,  5.1712e-01,\n",
      "         -1.0032e-01,  2.6273e-02, -4.3107e-01, -4.6714e-01,  8.7772e-03,\n",
      "         -9.8437e-02, -1.0327e-01,  1.5633e-01,  3.0277e-01, -3.3456e-01,\n",
      "          1.0320e-01,  1.8507e-01,  3.4345e-01, -5.4267e-02, -5.0361e-01,\n",
      "         -2.1154e-01,  9.4539e-01, -2.8267e-01,  6.4455e-01,  2.5747e-01,\n",
      "         -2.8927e-04,  5.3113e-02,  2.5619e-01,  1.7421e-01,  5.7446e-01,\n",
      "          2.2980e-01, -1.0613e-01, -1.6270e-01,  2.9367e-01,  6.3048e-01,\n",
      "          1.6375e-02,  3.0215e-01, -4.5938e-01, -1.0433e-01, -1.5250e-01,\n",
      "          4.7110e-01,  3.1251e-01, -2.5333e-01, -2.2990e-01, -9.3003e-02,\n",
      "         -5.5661e-01, -4.3179e-01, -1.2955e+00,  6.2999e-01,  7.5780e-01,\n",
      "         -3.7887e-01, -4.7100e-01,  3.7976e-01,  7.6504e-02,  5.7223e-01,\n",
      "         -3.5591e-01, -1.6539e-01,  2.8469e-02,  4.9591e-02, -8.4368e-01,\n",
      "          3.4688e-01, -3.1750e-01,  2.1745e-01, -8.8278e-02,  8.8912e-01,\n",
      "          4.1473e-01,  7.8695e-01, -2.7589e-01,  1.3156e-01,  4.5869e-01,\n",
      "         -9.1794e-02, -7.8897e-02,  5.7129e-01,  2.3025e-02, -2.7991e-01,\n",
      "         -8.1947e-02, -3.2388e-02,  7.1139e-01,  2.2960e-01,  1.8235e-01,\n",
      "          1.4190e-01, -7.5993e-02,  1.0237e-01,  5.6043e-02, -3.1258e-02,\n",
      "         -1.0575e+00,  1.8597e-01, -4.6418e-01,  4.9690e-01,  1.3595e-02,\n",
      "          1.2406e-03,  2.8390e-01,  8.3166e-01, -1.2547e-02, -3.0338e-01,\n",
      "         -5.7743e-01, -1.8082e-01,  2.1460e-01,  2.8078e-01,  7.3519e-01,\n",
      "         -1.0019e-01,  3.2342e-01, -2.4197e-01, -1.7068e-02, -1.7449e-01,\n",
      "          2.9441e-01,  4.9220e-02, -2.9391e-02,  3.7118e-01, -1.7966e-01,\n",
      "          2.6818e+00, -5.6904e-02, -1.1228e-01,  2.8034e-01,  4.4138e-01,\n",
      "         -2.5735e-01,  1.0356e-01, -3.2178e-01, -2.7392e-01, -2.9413e-01,\n",
      "          2.8523e-02,  5.9398e-01, -1.3214e-01,  3.0126e-01,  1.5257e-01,\n",
      "          1.2281e-01,  4.2680e-01, -6.1032e-01,  3.3779e-01, -2.0713e-01,\n",
      "          2.3392e-01, -1.7839e-01, -6.8475e-01,  4.4476e-01, -1.2075e+00,\n",
      "         -3.4041e-02, -3.3647e-01, -4.7297e-02,  3.4936e-01,  3.2729e-01,\n",
      "         -5.9383e-02,  7.4792e-02,  2.3996e-02, -3.8442e-01, -3.4061e-01,\n",
      "         -2.6159e-01,  1.1249e+00,  6.8559e-01, -4.0553e-02, -2.4708e-03,\n",
      "          1.9715e-01, -1.1762e-01, -6.2150e-01,  2.2158e-01, -6.8311e-01,\n",
      "         -1.3155e-01, -9.1484e-03,  3.4152e-01, -3.8565e-01,  9.8692e-02,\n",
      "         -3.6145e-01,  2.4486e-01, -8.2430e-02, -3.1649e-01, -1.0783e-01,\n",
      "         -6.3143e-01,  1.0733e-01, -3.0661e-04,  2.5585e-01,  6.3387e-02,\n",
      "         -6.6507e-01, -1.0352e-01, -3.3621e-01, -1.6418e-01, -4.4711e-01,\n",
      "          6.7539e-01, -2.8457e-01, -4.4403e-01,  2.6813e-02,  1.7595e-01,\n",
      "         -1.0978e-01,  7.4305e-01,  4.1162e-01, -2.1918e-01, -6.4005e-01,\n",
      "         -6.0737e-02,  6.0478e-01, -3.4264e-01, -1.3078e-01,  4.5774e-01,\n",
      "         -1.6359e-01, -9.6014e-02, -3.3855e-01, -2.5878e-01,  1.7739e-01,\n",
      "          3.7157e-02,  2.3682e-01,  2.8392e-01, -2.5629e-02,  4.9680e-01,\n",
      "         -5.5289e-01,  1.2387e-01,  8.3178e-02,  3.2470e-01, -3.2980e-01,\n",
      "         -4.7446e-01,  5.7040e-01, -2.3223e-02,  2.8380e-01,  2.4808e-02,\n",
      "         -4.8772e-01, -8.3283e-02, -1.1927e-01, -5.1934e+00, -3.3347e-01,\n",
      "         -1.3478e-01, -5.9000e-01,  1.5235e-01, -2.4514e-01,  9.7082e-01,\n",
      "          1.9883e-01, -3.4246e-01, -1.1679e-01,  4.0371e-01, -2.7715e-01,\n",
      "          4.9419e-01,  2.5457e-01,  5.1225e-01,  6.0200e-01, -4.2156e-02,\n",
      "         -2.4251e-01,  2.3827e-01, -3.6628e-02, -3.2454e-04, -5.2853e-01,\n",
      "          2.6703e-01, -1.7280e-01, -4.0289e-02, -3.5563e-02, -7.3025e-01,\n",
      "          3.7399e-01, -6.3901e-02, -2.2307e-01,  7.6909e-01, -5.4376e-02,\n",
      "          1.4134e-01,  5.3008e-02, -1.1964e-01,  1.6527e-01,  5.6163e-01,\n",
      "         -2.2395e-01,  9.3677e-02, -8.0197e-02,  4.6616e-01,  1.2768e-01,\n",
      "         -3.0683e-02,  6.9239e-02,  2.3355e-01, -4.2977e-01,  3.3633e-01,\n",
      "          7.3601e-02,  1.0163e-01,  4.6875e-01,  1.2553e-01, -1.3971e-01,\n",
      "          1.8918e-01, -1.7733e-01, -2.2540e-01, -7.5237e-02,  1.6326e-01,\n",
      "          2.3328e-01, -2.8115e-01,  6.1675e-02,  3.4955e-01, -5.4361e-02,\n",
      "          6.6350e-02, -7.3720e-01,  5.9153e-01, -1.7128e-01,  1.0735e-01,\n",
      "         -7.6582e-01,  1.7505e-01,  6.4935e-01, -1.0553e-01,  8.5844e-01,\n",
      "         -1.4110e-01, -1.6406e+00, -9.6258e-02, -6.8172e-02,  1.4445e-01,\n",
      "          2.8934e-01,  1.3416e-01,  4.9142e-01, -1.5740e-01, -1.0142e-01,\n",
      "          9.7084e-02,  3.6988e-01, -3.0071e-01, -2.3650e-01,  3.3513e-01,\n",
      "          3.5270e-01, -1.0274e+00, -1.7103e-01,  3.3949e-01,  3.0606e-02,\n",
      "          4.4648e-01,  3.3221e-01,  3.8190e-01,  6.2375e-01,  1.4077e-01,\n",
      "         -8.2322e-01,  5.5285e-01, -5.2119e-01,  7.2765e-01, -5.3592e-02,\n",
      "         -6.0490e-02, -6.6530e-01,  2.7797e-01, -1.9122e-01, -3.8600e-01,\n",
      "          2.0346e-01, -8.3807e-02, -3.5235e-02, -4.8243e-01,  3.2490e-02,\n",
      "         -3.8270e-02, -2.9881e-01,  1.4235e-01, -4.5777e-02,  1.3163e-01,\n",
      "          7.0282e-01, -1.5314e-01,  1.6719e-01,  1.5686e-01, -7.7783e-02,\n",
      "          2.7205e-01, -6.8286e-01, -2.1016e-01,  8.1514e-02, -4.5034e-01,\n",
      "          6.0989e-02, -1.4033e-01,  7.3023e-01, -4.7392e-02, -4.6906e-02,\n",
      "         -8.0194e-01, -2.8815e-01,  1.9830e-01, -3.3066e-03, -2.7979e-02,\n",
      "          9.0719e-02,  7.5844e-01, -3.8637e-01,  3.2810e-01, -6.9568e-01,\n",
      "         -7.4815e-01,  1.0080e-01, -4.5907e-02,  6.9524e-01, -1.5272e-01,\n",
      "         -2.5084e-01, -1.2198e-01,  2.3449e-01, -8.3075e-01, -7.9009e-01,\n",
      "          1.4155e-01, -3.8561e-01, -4.6169e-01, -9.2849e-02, -7.3887e-01,\n",
      "         -2.1116e-01, -6.1652e-01, -3.9191e-01, -1.0918e-01,  2.8889e-01,\n",
      "         -1.8786e+00,  8.6474e-02,  3.1791e-01,  2.1670e-01, -3.0904e-01,\n",
      "         -1.1658e+00, -2.8573e-02,  2.6107e-01, -4.5468e-01, -4.4335e-01,\n",
      "         -6.4044e-01,  1.2757e-01, -8.0202e-02,  1.1011e-01,  4.1566e-01,\n",
      "         -3.9525e-01, -7.0637e-02, -1.3741e-01,  4.6640e-02,  1.2296e-01,\n",
      "         -3.8535e-01,  3.6778e-01,  1.0293e+00, -3.2305e-02,  2.6723e-01,\n",
      "         -2.1579e-01,  3.6420e-02,  4.4958e-01,  5.4845e-02,  2.0292e-01,\n",
      "          1.2211e-01, -2.1712e-01,  1.2271e-02,  9.4772e-03,  8.7048e-01,\n",
      "          1.0023e+00,  1.4436e-01, -2.8117e-01,  8.2107e-01,  3.5348e-01,\n",
      "         -9.7398e-02,  7.0193e-02,  5.1788e-01,  4.4889e-01,  5.3529e-01,\n",
      "          4.7257e-01, -8.6475e-02, -2.9991e-01,  1.3980e-01, -3.1927e-01,\n",
      "         -3.0236e-02,  6.5265e-02, -3.0723e-01,  8.8895e-02,  1.9880e-01,\n",
      "         -1.0129e-01, -7.5288e-01,  4.4639e-01,  1.6293e-01, -2.0881e-01,\n",
      "         -4.5663e-01, -2.2671e-01, -4.7949e-01, -3.5929e-01,  3.6773e-01,\n",
      "         -7.6048e-01,  6.0304e-01, -4.2828e-01,  2.5695e-01,  7.2380e-01,\n",
      "          3.4536e-01,  9.4670e-02, -9.5884e-01,  1.0580e-01,  2.1310e-01,\n",
      "          1.3642e-01, -1.3779e-01, -1.5926e-01,  1.4942e-01, -3.2316e-01,\n",
      "          2.5974e-01, -6.8616e-01, -1.5415e-01,  1.0451e+00, -1.0968e-01,\n",
      "          2.2173e-01,  7.4635e-03,  3.8478e-01,  1.7174e-01,  4.1238e-01,\n",
      "         -7.4836e-01, -1.5237e-01, -8.8652e-01,  2.2205e-01, -3.5711e-01,\n",
      "          3.2795e-01,  9.7743e-02,  1.1769e-01, -7.3158e-01,  1.0314e-01,\n",
      "         -1.0864e-01, -5.7531e-01,  7.4455e-01,  4.7007e-01,  6.7996e-01,\n",
      "          3.8588e-01,  5.3975e-02,  1.6236e-01, -1.5934e-01, -2.1372e-01,\n",
      "          3.4893e-01, -8.9017e-02, -4.1790e-01,  2.7364e-01, -2.5039e-01,\n",
      "         -1.6093e-01,  7.0148e-01,  3.4836e-02,  7.0734e-01, -1.7064e-01,\n",
      "          1.0388e-01,  4.0075e-01,  3.6153e-01,  2.5505e-01, -8.2391e-02,\n",
      "         -1.5329e-01,  7.3571e-03,  5.5596e-01, -3.0381e-01,  5.2692e-01,\n",
      "         -4.8554e-01, -8.3559e-02,  6.0280e-01,  5.8168e-01,  1.7710e-01,\n",
      "         -3.2318e-01, -2.3413e-01,  3.6805e-01, -3.1271e-01, -2.9472e-01,\n",
      "          6.3041e-01, -2.6855e-01, -6.9744e-02,  3.1061e-01,  1.4752e-01,\n",
      "         -3.0914e-01,  3.2746e-01,  5.3078e-01,  3.2304e-02, -4.7226e-01,\n",
      "          6.9391e-01,  6.3121e-01, -5.0375e-01, -4.3235e-01, -7.3357e-01,\n",
      "          1.1285e-03, -6.9805e-01,  7.9527e-03,  7.8811e-02, -2.8014e-01,\n",
      "          8.5267e-01, -7.4057e-01, -1.6014e-01,  7.0653e-01, -4.4520e-01,\n",
      "         -1.4487e-01,  2.1016e-01,  3.2609e-01,  6.1783e-01,  8.0389e-02,\n",
      "          7.9312e-02,  4.4999e-02,  4.3982e-01, -4.5051e-01, -7.2895e-01,\n",
      "         -9.8776e-01, -5.9179e-01, -1.6834e-02,  6.6492e-02,  1.6143e-01,\n",
      "          5.1780e-01, -4.8438e-01, -4.3236e-01,  1.4026e-01,  4.5858e-01,\n",
      "          3.5269e-01,  7.9065e-01, -2.3065e-02, -3.2187e-01,  5.8639e-01,\n",
      "         -1.4363e-01,  3.7669e-02,  4.6435e-01,  2.8680e-01, -2.5156e-01,\n",
      "          5.8219e-02, -4.9658e-01, -5.8914e-01,  8.0899e-01,  4.1245e-01,\n",
      "         -2.8732e-01,  1.9251e-01,  2.8907e-01,  3.7965e-01,  1.6137e-01,\n",
      "          3.2546e-02, -2.2909e-01, -1.8921e-01,  5.4249e-01, -8.2254e-02,\n",
      "         -8.7163e-01,  4.8994e-01, -4.7713e-01,  6.1882e-02,  3.1666e-01,\n",
      "         -5.5854e-01, -6.5990e-01,  3.3878e-01,  2.6581e-01,  3.5331e-03,\n",
      "         -5.1904e-01, -5.1389e-01,  3.4893e-02,  1.9414e-01, -2.0872e-01,\n",
      "         -1.3820e-01, -4.6359e-02, -3.1966e-01, -6.4900e-01, -5.0541e-01,\n",
      "         -1.0403e-01,  1.3149e-01, -3.3739e-01, -3.2701e-01,  2.5295e-01,\n",
      "         -5.9876e-01,  2.9059e-01, -4.8120e-01,  5.6054e-01, -5.0624e-02,\n",
      "          2.9167e-01,  7.0504e-02, -1.1785e-02,  3.6631e-01, -4.6503e-01,\n",
      "          7.0678e-01, -4.6052e-01,  6.7136e-02,  1.1193e-02,  8.5650e-01,\n",
      "         -3.2825e-01,  3.5063e-01,  5.0797e-01, -7.3715e-03,  1.4287e-01,\n",
      "          1.8626e-01, -4.0522e-01, -8.4941e-01, -3.8983e-01, -6.0862e-02,\n",
      "         -4.8918e-02,  1.4690e-01,  2.7739e-01, -7.3028e-01, -1.2744e-01,\n",
      "         -1.1858e-02, -5.9031e-01, -5.3647e-02, -4.8565e-01, -1.0991e-01,\n",
      "          4.9265e-01, -2.2526e-01, -2.0694e-01,  9.8606e-01, -3.2760e-01,\n",
      "          5.6444e-02, -1.9503e-01,  2.0858e-01,  4.5363e-02, -7.8471e-02,\n",
      "          1.8088e-01,  8.8652e-01, -1.7306e+00, -5.5676e-01,  4.2978e-03,\n",
      "         -1.1088e-01, -5.6556e-01, -1.1275e+00, -1.9087e-02, -5.7258e-01,\n",
      "          5.6388e-02,  4.1795e-02,  2.0732e-01, -1.6663e-01, -2.4291e-01,\n",
      "         -5.0679e-01, -1.5592e-02,  1.6119e-01]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Récupérer les embeddings du premier token de la séquence\n",
    "print(output[0][:, 0, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OPTION CHATGPS qui marche pas (sauf si tu arrive a debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convertir les données tokenizées en tensors en utilisant la fonction \"encode_plus\" de la classe \"BertTokenizer\"\n",
    "# input_ids = tokenizer_BERT.encode_plus(\n",
    "#     avis_en_cleaned_str,  # Texte à tokenizer\n",
    "#     max_length=512,  # Longueur maximale de la séquence\n",
    "#     add_special_tokens=True,  # Ajouter les tokens spéciaux [CLS] et [SEP]\n",
    "#     return_token_type_ids=True,  # Générer des \"token type IDs\" pour chaque token\n",
    "#     pad_to_max_length=True,  # Remplir avec des zéros pour atteindre la longueur maximale\n",
    "#     return_attention_mask=True  # Générer un masque d'attention pour chaque token\n",
    "# )\n",
    "\n",
    "# # Générer les embeddings\n",
    "# output = model_BERT(**input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les embeddings du premier token de la séquence\n",
    "print(output[0][:, 0, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(text, model):\n",
    "    return np.mean([model.wv[word] for word in str(text).split()], axis=0)\n",
    "\n",
    "# Compute the embedding\n",
    "train['embedding'] = train['avis_en_cleaned'].apply(lambda x: compute_embedding(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>auteur</th>\n",
       "      <th>avis</th>\n",
       "      <th>assureur</th>\n",
       "      <th>produit</th>\n",
       "      <th>type</th>\n",
       "      <th>date_publication</th>\n",
       "      <th>date_exp</th>\n",
       "      <th>avis_en</th>\n",
       "      <th>avis_cor</th>\n",
       "      <th>avis_cor_en</th>\n",
       "      <th>avis_en_cleaned</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>brahim--k-131532</td>\n",
       "      <td>Meilleurs assurances, prix, solutions, écoute,...</td>\n",
       "      <td>Direct Assurance</td>\n",
       "      <td>auto</td>\n",
       "      <td>train</td>\n",
       "      <td>06/09/2021</td>\n",
       "      <td>01/09/2021</td>\n",
       "      <td>Best insurance, price, solutions, listening, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best insurance, price, solutions, listening, s...</td>\n",
       "      <td>[Best, insurance,, price,, solutions,, listeni...</td>\n",
       "      <td>[0.036845513, -0.09652644, 0.3273503, 0.390465...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>bernard-g-112497</td>\n",
       "      <td>je suis globalement satisfait , sauf que vous ...</td>\n",
       "      <td>Direct Assurance</td>\n",
       "      <td>auto</td>\n",
       "      <td>train</td>\n",
       "      <td>03/05/2021</td>\n",
       "      <td>01/05/2021</td>\n",
       "      <td>I am generally satisfied, except that you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I generally satisfied, except problem website,...</td>\n",
       "      <td>[I, generally, satisfied,, except, problem, we...</td>\n",
       "      <td>[0.12592742, -0.17508753, 0.12655705, 0.488717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>virginie-t-107352</td>\n",
       "      <td>Prix tres abordable plusieurs options s'offren...</td>\n",
       "      <td>Direct Assurance</td>\n",
       "      <td>auto</td>\n",
       "      <td>train</td>\n",
       "      <td>21/03/2021</td>\n",
       "      <td>01/03/2021</td>\n",
       "      <td>Very affordable price Several options are avai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very affordable price Several options availabl...</td>\n",
       "      <td>[Very, affordable, price, Several, options, av...</td>\n",
       "      <td>[0.09628583, -0.12933695, 0.22045308, 0.241730...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>boulain-f-116580</td>\n",
       "      <td>je satisfait du service, une réponse très rapi...</td>\n",
       "      <td>L'olivier Assurance</td>\n",
       "      <td>auto</td>\n",
       "      <td>train</td>\n",
       "      <td>10/06/2021</td>\n",
       "      <td>01/06/2021</td>\n",
       "      <td>I satisfy the service, a very fast response fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I satisfy service, fast response service. I th...</td>\n",
       "      <td>[I, satisfy, service,, fast, response, service...</td>\n",
       "      <td>[0.025221188, -0.10161609, 0.18565398, 0.49751...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ouaille31-51798</td>\n",
       "      <td>Client depuis plus de 25 ans, très déçu de cet...</td>\n",
       "      <td>Matmut</td>\n",
       "      <td>auto</td>\n",
       "      <td>train</td>\n",
       "      <td>29/01/2017</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>Customer for more than 25 years, very disappoi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer 25 years, disappointed \"mutual\" longe...</td>\n",
       "      <td>[Customer, 25, years,, disappointed, \"mutual\",...</td>\n",
       "      <td>[-0.054051913, -0.17967823, 0.14884299, 0.0384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>4</td>\n",
       "      <td>krys34-96609</td>\n",
       "      <td>J'ai jamais eu de soucis et toujours etait bie...</td>\n",
       "      <td>Assur O'Poil</td>\n",
       "      <td>animaux</td>\n",
       "      <td>train</td>\n",
       "      <td>24/08/2020</td>\n",
       "      <td>01/08/2020</td>\n",
       "      <td>I never had problems and always was well reimb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I never problems always well reimbursed dog ​​...</td>\n",
       "      <td>[I, never, problems, always, well, reimbursed,...</td>\n",
       "      <td>[-0.032576393, -0.13774587, 0.15680376, 0.2353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>3</td>\n",
       "      <td>fati-98297</td>\n",
       "      <td>Après 37 ans je quitte la Macif à la suite de ...</td>\n",
       "      <td>MACIF</td>\n",
       "      <td>auto</td>\n",
       "      <td>train</td>\n",
       "      <td>03/10/2020</td>\n",
       "      <td>01/10/2020</td>\n",
       "      <td>After 37 years I leave the Macif following sev...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After 37 years I leave Macif following several...</td>\n",
       "      <td>[After, 37, years, I, leave, Macif, following,...</td>\n",
       "      <td>[0.08294767, -0.14988041, 0.07407212, 0.309009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>1</td>\n",
       "      <td>jeremy59-96188</td>\n",
       "      <td>Je suis propriétaire d'une flotte de véhicules...</td>\n",
       "      <td>AXA</td>\n",
       "      <td>flotte-automobile</td>\n",
       "      <td>train</td>\n",
       "      <td>11/08/2020</td>\n",
       "      <td>01/08/2020</td>\n",
       "      <td>I own a fleet of motor vehicles which was insu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I fleet motor vehicles insured Axa Insurance m...</td>\n",
       "      <td>[I, fleet, motor, vehicles, insured, Axa, Insu...</td>\n",
       "      <td>[-0.084414475, -0.19338982, 0.20123054, 0.0992...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>1</td>\n",
       "      <td>mic-54375</td>\n",
       "      <td>Mutuelle à fuir. Chère. Remboursements insuffi...</td>\n",
       "      <td>Mgen</td>\n",
       "      <td>sante</td>\n",
       "      <td>train</td>\n",
       "      <td>29/04/2017</td>\n",
       "      <td>01/04/2017</td>\n",
       "      <td>Mutual to flee. Dear. Insufficient reimburseme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mutual flee. Dear. Insufficient reimbursements...</td>\n",
       "      <td>[Mutual, flee., Dear., Insufficient, reimburse...</td>\n",
       "      <td>[-0.06431994, -0.14848596, 0.12282439, -0.0018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>1</td>\n",
       "      <td>maylia-63603</td>\n",
       "      <td>Vol d'un bijou avec agression, expert nommé pa...</td>\n",
       "      <td>MAIF</td>\n",
       "      <td>habitation</td>\n",
       "      <td>train</td>\n",
       "      <td>06/05/2018</td>\n",
       "      <td>01/05/2018</td>\n",
       "      <td>Theft of a jewel with aggression, an expert na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Theft jewel aggression, expert named MAIF asse...</td>\n",
       "      <td>[Theft, jewel, aggression,, expert, named, MAI...</td>\n",
       "      <td>[0.019482536, -0.08784577, 0.15296537, 0.07587...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       note             auteur  \\\n",
       "0         5   brahim--k-131532   \n",
       "1         4   bernard-g-112497   \n",
       "2         5  virginie-t-107352   \n",
       "3         4   boulain-f-116580   \n",
       "4         1    ouaille31-51798   \n",
       "...     ...                ...   \n",
       "23995     4       krys34-96609   \n",
       "23996     3         fati-98297   \n",
       "23997     1     jeremy59-96188   \n",
       "23998     1          mic-54375   \n",
       "23999     1       maylia-63603   \n",
       "\n",
       "                                                    avis             assureur  \\\n",
       "0      Meilleurs assurances, prix, solutions, écoute,...     Direct Assurance   \n",
       "1      je suis globalement satisfait , sauf que vous ...     Direct Assurance   \n",
       "2      Prix tres abordable plusieurs options s'offren...     Direct Assurance   \n",
       "3      je satisfait du service, une réponse très rapi...  L'olivier Assurance   \n",
       "4      Client depuis plus de 25 ans, très déçu de cet...               Matmut   \n",
       "...                                                  ...                  ...   \n",
       "23995  J'ai jamais eu de soucis et toujours etait bie...         Assur O'Poil   \n",
       "23996  Après 37 ans je quitte la Macif à la suite de ...                MACIF   \n",
       "23997  Je suis propriétaire d'une flotte de véhicules...                  AXA   \n",
       "23998  Mutuelle à fuir. Chère. Remboursements insuffi...                 Mgen   \n",
       "23999  Vol d'un bijou avec agression, expert nommé pa...                 MAIF   \n",
       "\n",
       "                 produit   type date_publication    date_exp  \\\n",
       "0                   auto  train       06/09/2021  01/09/2021   \n",
       "1                   auto  train       03/05/2021  01/05/2021   \n",
       "2                   auto  train       21/03/2021  01/03/2021   \n",
       "3                   auto  train       10/06/2021  01/06/2021   \n",
       "4                   auto  train       29/01/2017  01/01/2017   \n",
       "...                  ...    ...              ...         ...   \n",
       "23995            animaux  train       24/08/2020  01/08/2020   \n",
       "23996               auto  train       03/10/2020  01/10/2020   \n",
       "23997  flotte-automobile  train       11/08/2020  01/08/2020   \n",
       "23998              sante  train       29/04/2017  01/04/2017   \n",
       "23999         habitation  train       06/05/2018  01/05/2018   \n",
       "\n",
       "                                                 avis_en  avis_cor  \\\n",
       "0      Best insurance, price, solutions, listening, s...       NaN   \n",
       "1      I am generally satisfied, except that you have...       NaN   \n",
       "2      Very affordable price Several options are avai...       NaN   \n",
       "3      I satisfy the service, a very fast response fr...       NaN   \n",
       "4      Customer for more than 25 years, very disappoi...       NaN   \n",
       "...                                                  ...       ...   \n",
       "23995  I never had problems and always was well reimb...       NaN   \n",
       "23996  After 37 years I leave the Macif following sev...       NaN   \n",
       "23997  I own a fleet of motor vehicles which was insu...       NaN   \n",
       "23998  Mutual to flee. Dear. Insufficient reimburseme...       NaN   \n",
       "23999  Theft of a jewel with aggression, an expert na...       NaN   \n",
       "\n",
       "       avis_cor_en                                    avis_en_cleaned  \\\n",
       "0              NaN  Best insurance, price, solutions, listening, s...   \n",
       "1              NaN  I generally satisfied, except problem website,...   \n",
       "2              NaN  Very affordable price Several options availabl...   \n",
       "3              NaN  I satisfy service, fast response service. I th...   \n",
       "4              NaN  Customer 25 years, disappointed \"mutual\" longe...   \n",
       "...            ...                                                ...   \n",
       "23995          NaN  I never problems always well reimbursed dog ​​...   \n",
       "23996          NaN  After 37 years I leave Macif following several...   \n",
       "23997          NaN  I fleet motor vehicles insured Axa Insurance m...   \n",
       "23998          NaN  Mutual flee. Dear. Insufficient reimbursements...   \n",
       "23999          NaN  Theft jewel aggression, expert named MAIF asse...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [Best, insurance,, price,, solutions,, listeni...   \n",
       "1      [I, generally, satisfied,, except, problem, we...   \n",
       "2      [Very, affordable, price, Several, options, av...   \n",
       "3      [I, satisfy, service,, fast, response, service...   \n",
       "4      [Customer, 25, years,, disappointed, \"mutual\",...   \n",
       "...                                                  ...   \n",
       "23995  [I, never, problems, always, well, reimbursed,...   \n",
       "23996  [After, 37, years, I, leave, Macif, following,...   \n",
       "23997  [I, fleet, motor, vehicles, insured, Axa, Insu...   \n",
       "23998  [Mutual, flee., Dear., Insufficient, reimburse...   \n",
       "23999  [Theft, jewel, aggression,, expert, named, MAI...   \n",
       "\n",
       "                                               embedding  \n",
       "0      [0.036845513, -0.09652644, 0.3273503, 0.390465...  \n",
       "1      [0.12592742, -0.17508753, 0.12655705, 0.488717...  \n",
       "2      [0.09628583, -0.12933695, 0.22045308, 0.241730...  \n",
       "3      [0.025221188, -0.10161609, 0.18565398, 0.49751...  \n",
       "4      [-0.054051913, -0.17967823, 0.14884299, 0.0384...  \n",
       "...                                                  ...  \n",
       "23995  [-0.032576393, -0.13774587, 0.15680376, 0.2353...  \n",
       "23996  [0.08294767, -0.14988041, 0.07407212, 0.309009...  \n",
       "23997  [-0.084414475, -0.19338982, 0.20123054, 0.0992...  \n",
       "23998  [-0.06431994, -0.14848596, 0.12282439, -0.0018...  \n",
       "23999  [0.019482536, -0.08784577, 0.15296537, 0.07587...  \n",
       "\n",
       "[24000 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data in pickle format\n",
    "train.to_pickle('datasets/all_train_data_embedding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('models/word2vec.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72db1283cdc3edc3e05ca6272062c06a23afc2ae71a79b6442f05a0b53e87d43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
